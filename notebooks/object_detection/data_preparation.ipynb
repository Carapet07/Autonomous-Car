{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# BDD100K Dataset - Data Preparation\n",
    "\n",
    "This notebook converts BDD100K annotations from JSON format to YOLO format for object detection training.\n",
    "\n",
    "## Overview\n",
    "- Load BDD100K JSON annotations\n",
    "- Convert bounding boxes to YOLO format\n",
    "- Create YOLO configuration file\n",
    "- Organize dataset structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdec354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import yaml\n",
    "\n",
    "# Dataset paths\n",
    "dataset_dir = Path(\"../../Datasets/ObjectDetectionSet/bdd100k\")\n",
    "images_dir = dataset_dir / \"bdd100k/bdd100k/images/100k\"\n",
    "annotations_dir = dataset_dir / \"bdd100k_labels_release/bdd100k/labels\"\n",
    "\n",
    "# Output directories for YOLO format\n",
    "output_dir = dataset_dir / \"yolo_format\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    (output_dir / 'images' / split).mkdir(parents=True, exist_ok=True)\n",
    "    (output_dir / 'labels' / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Dataset directory: {dataset_dir}\")\n",
    "print(f\"üìÅ Images directory: {images_dir}\")\n",
    "print(f\"üìÅ Annotations directory: {annotations_dir}\")\n",
    "print(f\"üìÅ Output directory: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1916663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BDD100K class mapping to YOLO format\n",
    "class_mapping = {\n",
    "    'pedestrian': 0,\n",
    "    'rider': 1,\n",
    "    'car': 2,\n",
    "    'truck': 3,\n",
    "    'bus': 4,\n",
    "    'train': 5,\n",
    "    'motorcycle': 6,\n",
    "    'bicycle': 7,\n",
    "    'traffic light': 8,\n",
    "    'traffic sign': 9\n",
    "}\n",
    "\n",
    "# BDD100K category mapping (from JSON to our classes)\n",
    "bdd_to_yolo = {\n",
    "    'person': 'pedestrian',\n",
    "    'rider': 'rider',\n",
    "    'car': 'car',\n",
    "    'truck': 'truck',\n",
    "    'bus': 'bus',\n",
    "    'train': 'train',\n",
    "    'motorcycle': 'motorcycle',\n",
    "    'bike': 'bicycle',\n",
    "    'traffic light': 'traffic light',\n",
    "    'traffic sign': 'traffic sign'\n",
    "}\n",
    "\n",
    "class_names = list(class_mapping.keys())\n",
    "print(f\"üìã Number of classes: {len(class_names)}\")\n",
    "print(f\"üìã Classes: {class_names}\")\n",
    "print(f\"üìã Class mapping: {class_mapping}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dec417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotation files\n",
    "train_annotations_file = annotations_dir / \"bdd100k_labels_images_train.json\"\n",
    "val_annotations_file = annotations_dir / \"bdd100k_labels_images_val.json\"\n",
    "\n",
    "print(f\"üìã Loading train annotations from: {train_annotations_file}\")\n",
    "with open(train_annotations_file, 'r') as f:\n",
    "    train_annotations = json.load(f)\n",
    "\n",
    "print(f\"üìã Loading validation annotations from: {val_annotations_file}\")\n",
    "with open(val_annotations_file, 'r') as f:\n",
    "    val_annotations = json.load(f)\n",
    "\n",
    "print(f\"üìä Train annotations: {len(train_annotations)}\")\n",
    "print(f\"üìä Validation annotations: {len(val_annotations)}\")\n",
    "\n",
    "# Analyze annotation structure\n",
    "sample_annotation = train_annotations[0]\n",
    "print(f\"\\nüìã Sample annotation structure:\")\n",
    "print(f\"  Image name: {sample_annotation['name']}\")\n",
    "print(f\"  Number of labels: {len(sample_annotation['labels'])}\")\n",
    "print(f\"  Attributes: {sample_annotation['attributes']}\")\n",
    "\n",
    "if sample_annotation['labels']:\n",
    "    sample_label = sample_annotation['labels'][0]\n",
    "    print(f\"  Sample label category: {sample_label['category']}\")\n",
    "    print(f\"  Sample label box2d: {sample_label['box2d']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad81582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bbox_to_yolo(box2d, img_width=1280, img_height=720):\n",
    "    \"\"\"\n",
    "    Convert BDD100K bounding box format to YOLO format.\n",
    "    \n",
    "    Args:\n",
    "        box2d: Dictionary with x1, y1, x2, y2 coordinates\n",
    "        img_width: Image width (default: 1280 for BDD100K)\n",
    "        img_height: Image height (default: 720 for BDD100K)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (center_x, center_y, width, height) normalized to [0,1]\n",
    "    \"\"\"\n",
    "    x1, y1 = box2d['x1'], box2d['y1']\n",
    "    x2, y2 = box2d['x2'], box2d['y2']\n",
    "    \n",
    "    # Calculate center coordinates\n",
    "    center_x = (x1 + x2) / 2\n",
    "    center_y = (y1 + y2) / 2\n",
    "    \n",
    "    # Calculate width and height\n",
    "    width = x2 - x1\n",
    "    height = y2 - y1\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    center_x_norm = center_x / img_width\n",
    "    center_y_norm = center_y / img_height\n",
    "    width_norm = width / img_width\n",
    "    height_norm = height / img_height\n",
    "    \n",
    "    return center_x_norm, center_y_norm, width_norm, height_norm\n",
    "\n",
    "# Test the conversion function\n",
    "if sample_annotation['labels']:\n",
    "    sample_box2d = sample_annotation['labels'][0]['box2d']\n",
    "    yolo_coords = convert_bbox_to_yolo(sample_box2d)\n",
    "    print(f\"üìê Original box2d: {sample_box2d}\")\n",
    "    print(f\"üìê YOLO format: {yolo_coords}\")\n",
    "    \n",
    "    # Verify conversion\n",
    "    center_x, center_y, width, height = yolo_coords\n",
    "    print(f\"üìê Center: ({center_x:.3f}, {center_y:.3f})\")\n",
    "    print(f\"üìê Size: {width:.3f} x {height:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a9f7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_annotations(annotations, split_name):\n",
    "    \"\"\"\n",
    "    Process annotations and convert to YOLO format.\n",
    "    \n",
    "    Args:\n",
    "        annotations: List of annotation dictionaries\n",
    "        split_name: Name of the split (train/val/test)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary mapping image names to YOLO labels\n",
    "    \"\"\"\n",
    "    yolo_labels = {}\n",
    "    \n",
    "    for annotation in tqdm(annotations, desc=f\"Processing {split_name} annotations\"):\n",
    "        image_name = annotation['name']\n",
    "        yolo_lines = []\n",
    "        \n",
    "        for label in annotation['labels']:\n",
    "            category = label['category']\n",
    "            \n",
    "            # Map BDD100K category to our class\n",
    "            if category in bdd_to_yolo:\n",
    "                yolo_class = bdd_to_yolo[category]\n",
    "                class_id = class_mapping[yolo_class]\n",
    "                \n",
    "                # Convert bounding box\n",
    "                if 'box2d' in label:\n",
    "                    center_x, center_y, width, height = convert_bbox_to_yolo(label['box2d'])\n",
    "                    \n",
    "                    # Create YOLO format line\n",
    "                    yolo_line = f\"{class_id} {center_x:.6f} {center_y:.6f} {width:.6f} {height:.6f}\"\n",
    "                    yolo_lines.append(yolo_line)\n",
    "        \n",
    "        if yolo_lines:\n",
    "            yolo_labels[image_name] = yolo_lines\n",
    "    \n",
    "    return yolo_labels\n",
    "\n",
    "# Process train and validation annotations\n",
    "print(\"üîÑ Processing train annotations...\")\n",
    "train_yolo_labels = process_annotations(train_annotations, \"train\")\n",
    "\n",
    "print(\"üîÑ Processing validation annotations...\")\n",
    "val_yolo_labels = process_annotations(val_annotations, \"val\")\n",
    "\n",
    "print(f\"üìä Train images with labels: {len(train_yolo_labels)}\")\n",
    "print(f\"üìä Validation images with labels: {len(val_yolo_labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d591554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images_and_create_labels(split_name, yolo_labels):\n",
    "    \"\"\"\n",
    "    Copy images and create YOLO label files for a split.\n",
    "    \n",
    "    Args:\n",
    "        split_name: Name of the split (train/val/test)\n",
    "        yolo_labels: Dictionary of YOLO labels\n",
    "    \"\"\"\n",
    "    images_source_dir = images_dir / split_name\n",
    "    images_dest_dir = output_dir / 'images' / split_name\n",
    "    labels_dest_dir = output_dir / 'labels' / split_name\n",
    "    \n",
    "    copied_count = 0\n",
    "    label_count = 0\n",
    "    \n",
    "    for image_name, yolo_lines in tqdm(yolo_labels.items(), desc=f\"Processing {split_name}\"):\n",
    "        # Copy image\n",
    "        source_image = images_source_dir / image_name\n",
    "        dest_image = images_dest_dir / image_name\n",
    "        \n",
    "        if source_image.exists():\n",
    "            shutil.copy2(source_image, dest_image)\n",
    "            copied_count += 1\n",
    "            \n",
    "            # Create label file\n",
    "            label_filename = image_name.replace('.jpg', '.txt')\n",
    "            label_file = labels_dest_dir / label_filename\n",
    "            \n",
    "            with open(label_file, 'w') as f:\n",
    "                f.write('\\n'.join(yolo_lines))\n",
    "            \n",
    "            label_count += 1\n",
    "    \n",
    "    return copied_count, label_count\n",
    "\n",
    "# Process train split\n",
    "print(\"üìÅ Processing train split...\")\n",
    "train_images, train_labels = copy_images_and_create_labels(\"train\", train_yolo_labels)\n",
    "\n",
    "# Process validation split\n",
    "print(\"üìÅ Processing validation split...\")\n",
    "val_images, val_labels = copy_images_and_create_labels(\"val\", val_yolo_labels)\n",
    "\n",
    "print(f\"‚úÖ Train: {train_images} images, {train_labels} labels\")\n",
    "print(f\"‚úÖ Validation: {val_images} images, {val_labels} labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df18e2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create YOLO configuration\n",
    "yolo_config = {\n",
    "    'path': str(output_dir.absolute()),  # Dataset root directory\n",
    "    'train': 'images/train',  # Train images (relative to 'path')\n",
    "    'val': 'images/val',      # Validation images (relative to 'path')\n",
    "    'test': 'images/test',    # Test images (relative to 'path')\n",
    "    'nc': len(class_names),   # Number of classes\n",
    "    'names': class_names      # Class names\n",
    "}\n",
    "\n",
    "# Save configuration\n",
    "config_file = output_dir / 'data.yaml'\n",
    "with open(config_file, 'w') as f:\n",
    "    yaml.dump(yolo_config, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f\"üìù YOLO configuration saved to: {config_file}\")\n",
    "print(f\"üìã Configuration:\")\n",
    "for key, value in yolo_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\n‚úÖ YOLO format conversion completed!\")\n",
    "print(f\"üìÅ Output directory: {output_dir}\")\n",
    "print(f\"üìù Configuration file: {config_file}\")\n",
    "print(f\"üöÄ Ready for YOLO training!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
